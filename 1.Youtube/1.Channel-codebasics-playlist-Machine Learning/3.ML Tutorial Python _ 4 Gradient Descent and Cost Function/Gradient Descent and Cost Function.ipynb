{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Gradient Descent and Cost Function.csv')\n",
    "x = np.array(df['math'])\n",
    "y = np.array(df['cs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m 791.344, b 11.184000000000001, cost 5199.1, difference from current cost-5199.1, iteration 0\n",
      "m -597932.4459520001, b -8437.306111999998, cost 2957909051.2312264, difference from current cost-2957903852.1312265, iteration 1\n",
      "m 452390988.68765604, b 6383625.829200897, cost 1693194866633649.8, difference from current cost-1693191908724598.5, iteration 2\n",
      "m -342274866884.40906, b -4829792630.21314, cost 9.692349688813365e+20, difference from current cost-9.692332756864699e+20, iteration 3\n",
      "m 258962021130465.47, b 3654176751462.369, cost 5.548188477384989e+26, difference from current cost-5.5481787850353e+26, iteration 4\n",
      "m -1.9592828710504816e+17, b -2764716573371175.5, cost 3.17594766686098e+32, difference from current cost-3.175942118672503e+32, iteration 5\n",
      "m 1.4823754278847883e+20, b 2.0917591706571228e+18, cost 1.8180066563625124e+38, difference from current cost-1.8180034804148455e+38, iteration 6\n",
      "m -1.1215516358893291e+23, b -1.5826057796199097e+21, cost 1.0406809397602957e+44, difference from current cost-1.0406791217536395e+44, iteration 7\n",
      "m 8.4855566835785e+25, b 1.1973849995836343e+24, cost 5.957166408550363e+49, difference from current cost-5.957156001740966e+49, iteration 8\n",
      "m -6.420094262813677e+28, b -9.059304949412198e+26, cost 3.4100587666508905e+55, difference from current cost-3.410052809484482e+55, iteration 9\n",
      "m 4.857384362675771e+31, b 6.854186931937754e+29, cost 1.9520187945937058e+61, difference from current cost-1.9520153845349392e+61, iteration 10\n",
      "m -3.6750524028017463e+34, b -5.1858148898050375e+32, cost 1.1173934630426721e+67, difference from current cost-1.1173915110238775e+67, iteration 11\n",
      "m 2.7805108994707753e+37, b 3.9235399236070706e+35, cost 6.396291647951953e+72, difference from current cost-6.396280474017323e+72, iteration 12\n",
      "m -2.1037090127427084e+40, b -2.9685142758185342e+38, cost 3.6614270799700817e+78, difference from current cost-3.6614206836784338e+78, iteration 13\n",
      "m 1.591646920404894e+43, b 2.2459506408277197e+41, cost 2.0959094737699718e+84, difference from current cost-2.095905812342892e+84, iteration 14\n",
      "m -1.2042254436755699e+46, b -1.6992656299904556e+44, cost 1.199760756200726e+90, difference from current cost-1.1997586602912523e+90, iteration 15\n",
      "m 9.111059121244814e+48, b 1.2856487710712573e+47, cost 6.867786467562465e+95, difference from current cost-6.867774469954903e+95, iteration 16\n",
      "m -6.893343663080948e+51, b -9.72710053910946e+49, cost 3.931324701217591e+101, difference from current cost-3.931317833431123e+101, iteration 17\n",
      "m 5.215440513006573e+54, b 7.359434942648065e+52, cost 2.2504068784609466e+107, difference from current cost-2.2504029471362455e+107, iteration 18\n",
      "m -3.9459543980653636e+57, b -5.568080894949602e+55, cost 1.2881996536831072e+113, difference from current cost-1.2881974032762288e+113, iteration 19\n",
      "m 2.985472861358616e+60, b 4.2127588727005036e+58, cost 7.3740369514164525e+118, difference from current cost-7.374024069419915e+118, iteration 20\n",
      "m -2.258781350914425e+63, b -3.187334676767021e+61, cost 4.221117495675996e+124, difference from current cost-4.2211101216390446e+124, iteration 21\n",
      "m 1.7089732274159606e+66, b 2.4115081467288536e+64, cost 2.4162928704716373e+130, difference from current cost-2.4162886493541416e+130, iteration 22\n",
      "m -1.2929934501372517e+69, b -1.8245249186189264e+67, cost 1.3831577163802824e+136, difference from current cost-1.383155300087412e+136, iteration 23\n",
      "m 9.782669706451249e+71, b 1.380418798575055e+70, cost 7.917605070816164e+141, difference from current cost-7.917591239239001e+141, iteration 24\n",
      "m -7.401478064359901e+74, b -1.0444121864347067e+73, cost 4.532272011717456e+147, difference from current cost-4.5322640941123856e+147, iteration 25\n",
      "m 5.599890334749264e+77, b 7.90192669282181e+75, cost 2.59440694559421e+153, difference from current cost-2.5944024133221985e+153, iteration 26\n",
      "m -4.236825602742662e+80, b -5.978525171358044e+78, cost 1.485115496586634e+159, difference from current cost-1.4851129021796884e+159, iteration 27\n",
      "m 3.2055433437089737e+83, b 4.523297243067417e+81, cost 8.501241649646501e+164, difference from current cost-8.501226798491536e+164, iteration 28\n",
      "m -2.4252846569245555e+86, b -3.422285156071976e+84, cost 4.866362902534593e+170, difference from current cost-4.866354401292943e+170, iteration 29\n",
      "m 1.8349480997214922e+89, b 2.5892695217898647e+87, cost 2.785650482026897e+176, difference from current cost-2.7856456156639943e+176, iteration 30\n",
      "m -1.3883048816798148e+92, b -1.9590175425840277e+90, cost 1.5945889699214695e+182, difference from current cost-1.5945861842709874e+182, iteration 31\n",
      "m 1.0503787244928306e+95, b 1.4821746828036159e+93, cost 9.127900285412262e+187, difference from current cost-9.127884339522563e+187, iteration 32\n",
      "m -7.947068971854548e+97, b -1.1213997540043824e+96, cost 5.225080894955175e+193, difference from current cost-5.22507176705489e+193, iteration 33\n",
      "m 6.012679405126735e+100, b 8.484407559184506e+98, cost 2.9909913019599242e+199, difference from current cost-2.9909860768790294e+199, iteration 34\n",
      "m -4.5491380226939934e+103, b -6.41922484584974e+101, cost 1.7121321465161096e+205, difference from current cost-1.7121291555248078e+205, iteration 35\n",
      "m 3.4418360526381695e+106, b 4.856726569784827e+104, cost 9.800752296447631e+210, difference from current cost-9.800735175126166e+210, iteration 36\n",
      "m -2.604061550593395e+109, b -3.674554722741057e+107, cost 5.610241345668219e+216, difference from current cost-5.610231544915923e+216, iteration 37\n",
      "m 1.9702090557396345e+112, b 2.7801343593071186e+110, cost 3.211468569413128e+222, difference from current cost-3.2114629591717824e+222, iteration 38\n",
      "m -1.490642078884012e+115, b -2.103424125912704e+113, cost 1.8383398746814523e+228, difference from current cost-1.838336663212883e+228, iteration 39\n",
      "m 1.1278061081215996e+118, b 1.591431377645465e+116, cost 1.0523202770941003e+234, difference from current cost-1.0523184387542256e+234, iteration 40\n",
      "m -8.532877446131456e+120, b -1.2040623660031437e+119, cost 6.023793428161866e+239, difference from current cost-6.023782904959095e+239, iteration 41\n",
      "m 6.455896717208464e+123, b 9.109825290550875e+121, cost 3.4481980491117457e+245, difference from current cost-3.4481920253183175e+245, iteration 42\n",
      "m -4.8844721708922254e+126, b -6.892410158108345e+124, cost 1.973850851244455e+251, difference from current cost-1.9738474030464058e+251, iteration 43\n",
      "m 3.695546789747414e+129, b 5.2147342317168e+127, cost 1.1298907798993999e+257, difference from current cost-1.1298888060485486e+257, iteration 44\n",
      "m -2.7960167644312197e+132, b -3.9454200321273945e+130, cost 6.467829996865172e+262, difference from current cost-6.467818697957373e+262, iteration 45\n",
      "m 2.1154406077793855e+135, b 2.9850685649971e+133, cost 3.7023777530137465e+268, difference from current cost-3.7023712851837496e+268, iteration 46\n",
      "m -1.6005229374768654e+138, b -2.25847546400001e+136, cost 2.11935085378789e+274, difference from current cost-2.119347151410137e+274, iteration 47\n",
      "m 1.2109409566825924e+141, b 1.708741796185514e+139, cost 1.2131792974920625e+280, difference from current cost-1.2131771781412086e+280, iteration 48\n",
      "m -9.161868075961564e+143, b -1.2928183513935592e+142, cost 6.944598178412964e+285, difference from current cost-6.944586046619989e+285, iteration 49\n",
      "m 6.931785251634338e+146, b 9.781344925436015e+144, cost 3.9752940030640607e+291, difference from current cost-3.9752870584658825e+291, iteration 50\n",
      "m -5.24452506589191e+149, b -7.400475747209413e+147, cost 2.2755762111507092e+297, difference from current cost-2.275572235856706e+297, iteration 51\n",
      "m 3.9679595036911384e+152, b 5.599131990797618e+150, cost 1.302607326342089e+303, difference from current cost-1.3026050507658778e+303, iteration 52\n",
      "m -3.002121722199301e+155, b -4.236251846672819e+153, cost inf, difference from current cost-inf, iteration 53\n",
      "m 2.271377726137812e+158, b 3.205109245135408e+156, cost inf, difference from current costnan, iteration 54\n",
      "m -1.718503529235807e+161, b -2.4249562219301798e+159, cost inf, difference from current costnan, iteration 55\n",
      "m 1.3002039889761339e+164, b 1.8346996088208093e+162, cost inf, difference from current costnan, iteration 56\n",
      "m -9.837223981152977e+166, b -1.3881168757462824e+165, cost inf, difference from current costnan, iteration 57\n",
      "m 7.442753327620155e+169, b 1.0502364809300033e+168, cost inf, difference from current costnan, iteration 58\n",
      "m -5.631118819895808e+172, b -7.94599277012061e+170, cost inf, difference from current costnan, iteration 59\n",
      "m 4.260452787829256e+175, b 6.011865160777739e+173, cost inf, difference from current costnan, iteration 60\n",
      "m -3.2234194549739468e+178, b -4.548521972896855e+176, cost inf, difference from current costnan, iteration 61\n",
      "m 2.4388095585489555e+181, b 3.441369955018922e+179, cost inf, difference from current costnan, iteration 62\n",
      "m -1.8451809160895643e+184, b -2.603708905414908e+182, cost inf, difference from current costnan, iteration 63\n",
      "m 1.3960469365746011e+187, b 1.9699422476359784e+185, cost inf, difference from current costnan, iteration 64\n",
      "m -1.0562362921299188e+190, b -1.4904402143229195e+188, cost inf, difference from current costnan, iteration 65\n",
      "m 7.991386790688628e+192, b 1.1276533792484262e+191, cost inf, difference from current costnan, iteration 66\n",
      "m -6.046209859880246e+195, b -8.531721913502319e+193, cost inf, difference from current costnan, iteration 67\n",
      "m 4.5745068568459293e+198, b 6.455022451832666e+196, cost inf, difference from current costnan, iteration 68\n",
      "m -3.461029879592188e+201, b -4.88381070973739e+199, cost inf, difference from current costnan, iteration 69\n",
      "m 2.618583423807371e+204, b 3.6950463343119505e+202, cost inf, difference from current costnan, iteration 70\n",
      "m -1.9811961716570593e+207, b -2.7956381244444965e+205, cost inf, difference from current costnan, iteration 71\n",
      "m 1.4989548298910064e+210, b 2.115154132242531e+208, cost inf, difference from current costnan, iteration 72\n",
      "m -1.134095459196407e+213, b -1.6003061927164237e+211, cost inf, difference from current costnan, iteration 73\n",
      "m 8.580462098804075e+215, b 1.2107769695872383e+214, cost inf, difference from current costnan, iteration 74\n",
      "m -6.491898828444448e+218, b -9.160627364657263e+216, cost inf, difference from current costnan, iteration 75\n",
      "m 4.9117110376412535e+221, b 6.930846540855114e+219, cost inf, difference from current costnan, iteration 76\n",
      "m -3.716155466191636e+224, b -5.243814845936654e+222, cost inf, difference from current costnan, iteration 77\n",
      "m 2.8116090997767347e+227, b 3.967422157795034e+225, cost inf, difference from current costnan, iteration 78\n",
      "m -2.127237625515338e+230, b -3.0017151712288265e+228, cost inf, difference from current costnan, iteration 79\n",
      "m 1.6094484527623233e+233, b 2.2710701334069613e+231, cost inf, difference from current costnan, iteration 80\n",
      "m -1.2176939195833907e+236, b -1.7182708074003094e+234, cost inf, difference from current costnan, iteration 81\n",
      "m 9.212960373135552e+238, b 1.3000279137725117e+237, cost inf, difference from current costnan, iteration 82\n",
      "m -6.970441214488896e+241, b -9.83589181233159e+239, cost inf, difference from current costnan, iteration 83\n",
      "m 5.2737718124048815e+244, b 7.441745420923376e+242, cost inf, difference from current costnan, iteration 84\n",
      "m -3.990087323526137e+247, b -5.630356246944762e+245, cost inf, difference from current costnan, iteration 85\n",
      "m 3.0188634274837846e+250, b 4.259875832137302e+248, cost inf, difference from current costnan, iteration 86\n",
      "m -2.2840443466147725e+253, b -3.2229829355956745e+251, cost inf, difference from current costnan, iteration 87\n",
      "m 1.7280869779694343e+256, b 2.4384792919959686e+254, cost inf, difference from current costnan, iteration 88\n",
      "m -1.3074547382819278e+259, b -1.844931039448455e+257, cost inf, difference from current costnan, iteration 89\n",
      "m 9.89208248455478e+261, b 1.395857882202588e+260, cost inf, difference from current costnan, iteration 90\n",
      "m -7.484258767521117e+264, b -1.0560932553281647e+263, cost inf, difference from current costnan, iteration 91\n",
      "m 5.66252145457497e+267, b 7.990304587381815e+265, cost inf, difference from current costnan, iteration 92\n",
      "m -4.284211732852989e+270, b -6.045391074796326e+268, cost inf, difference from current costnan, iteration 93\n",
      "m 3.241395254597389e+273, b 4.573887371570446e+271, cost inf, difference from current costnan, iteration 94\n",
      "m -2.452409883469923e+276, b -3.460561182721571e+274, cost inf, difference from current costnan, iteration 95\n",
      "m 1.8554707970311978e+279, b 2.618228812059168e+277, cost inf, difference from current costnan, iteration 96\n",
      "m -1.4038321660017122e+282, b -1.9809278756648144e+280, cost inf, difference from current costnan, iteration 97\n",
      "m 1.0621265252216863e+285, b 1.4987518396070714e+283, cost inf, difference from current costnan, iteration 98\n",
      "m -8.035951753353097e+287, b -1.1339418786116686e+286, cost inf, difference from current costnan, iteration 99\n",
      "m 6.0799273013862775e+290, b 8.579300122203452e+288, cost inf, difference from current costnan, iteration 100\n",
      "m -4.6000171634576964e+293, b -6.491019687619003e+291, cost inf, difference from current costnan, iteration 101\n",
      "m 3.480330743310152e+296, b 4.911045887765987e+294, cost inf, difference from current costnan, iteration 102\n",
      "m -2.6331862800540167e+299, b -3.715652219904167e+297, cost inf, difference from current costnan, iteration 103\n",
      "m 1.9922445585933236e+302, b 2.8112283482570136e+300, cost inf, difference from current costnan, iteration 104\n",
      "m -1.5073139379881955e+305, b -2.126949552412009e+303, cost inf, difference from current costnan, iteration 105\n",
      "m inf, b 1.609230499297757e+306, cost inf, difference from current costnan, iteration 106\n",
      "m nan, b -inf, cost inf, difference from current costnan, iteration 107\n",
      "m nan, b nan, cost nan, difference from current costnan, iteration 108\n",
      "m nan, b nan, cost nan, difference from current costnan, iteration 109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-3050e35cc46d>:10: RuntimeWarning: overflow encountered in double_scalars\n",
      "  cost = (1/n) * sum([val**2 for val in (y-y_predicted)])\n",
      "<ipython-input-16-3050e35cc46d>:15: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  diff_cost=cost_prv-cost\n",
      "<ipython-input-16-3050e35cc46d>:11: RuntimeWarning: overflow encountered in multiply\n",
      "  md = -(2/n)*sum(x*(y-y_predicted))\n",
      "<ipython-input-16-3050e35cc46d>:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  m_curr = m_curr - learning_rate * md\n"
     ]
    }
   ],
   "source": [
    "def gradient_descent(x,y):\n",
    "    m_curr = b_curr = 0\n",
    "    iterations = 110\n",
    "    n = len(x)\n",
    "    learning_rate = 0.08\n",
    "    cost_prv=0\n",
    "    diff_cost=0\n",
    "    for i in range(iterations):\n",
    "        y_predicted = m_curr * x + b_curr\n",
    "        cost = (1/n) * sum([val**2 for val in (y-y_predicted)])\n",
    "        md = -(2/n)*sum(x*(y-y_predicted))\n",
    "        bd = -(2/n)*sum(y-y_predicted)\n",
    "        m_curr = m_curr - learning_rate * md\n",
    "        b_curr = b_curr - learning_rate * bd\n",
    "        diff_cost=cost_prv-cost\n",
    "        cost_prv=cost\n",
    "        if cost <= 1e-20:\n",
    "            break\n",
    "        print (\"m {}, b {}, cost {}, difference from current cost{}, iteration {}\".format(m_curr,b_curr,cost,diff_cost, i),end=\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "gradient_descent(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
